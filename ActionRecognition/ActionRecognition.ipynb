{"cells":[{"cell_type":"code","execution_count":17,"metadata":{"id":"9yXMAyqOXdIr","executionInfo":{"status":"ok","timestamp":1707413158874,"user_tz":-300,"elapsed":27853,"user":{"displayName":"Maaz Khan","userId":"04955131875596241974"}}},"outputs":[],"source":["%%capture\n","\n","!pip install moviepy\n","\n","!pip3 install imageio==2.4.1\n","\n","!pip install --upgrade imageio-ffmpeg\n","!pip install pafy youtube-dl\n","!pip install pytube\n","!pip install moviepy"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"uXhNoLoyYSUR","executionInfo":{"status":"ok","timestamp":1707413158875,"user_tz":-300,"elapsed":28,"user":{"displayName":"Maaz Khan","userId":"04955131875596241974"}}},"outputs":[],"source":["#importing libraries\n","import os\n","import cv2\n","import pafy\n","import math\n","import random\n","import numpy as np\n","import datetime as dt\n","import tensorflow as tf\n","from collections import deque\n","import matplotlib.pyplot as plt\n","from moviepy.editor import *\n","from sklearn.model_selection import train_test_split\n","from keras.layers import *\n","from keras.models import Sequential\n","from keras.utils import to_categorical\n","from keras.callbacks import EarlyStopping\n","from keras.backend import dropout\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, SimpleRNN, Dense, Flatten, Dropout, TimeDistributed\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1707413158875,"user":{"displayName":"Maaz Khan","userId":"04955131875596241974"},"user_tz":-300},"id":"ZZKczD_DZP00","outputId":"10769afc-c49a-412c-e7b8-799e52485451"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.2856054152322811"]},"metadata":{},"execution_count":19}],"source":["seed_constant = 27\n","np.random.seed(seed_constant)\n","np.random.randn()"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"UX2GYhZCZNqb","executionInfo":{"status":"ok","timestamp":1707413158875,"user_tz":-300,"elapsed":20,"user":{"displayName":"Maaz Khan","userId":"04955131875596241974"}}},"outputs":[],"source":["seed_constant = 27\n","np.random.seed(seed_constant)\n","random.seed(seed_constant)\n","tf.random.set_seed(seed_constant)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CCP3INu1ZSpR"},"outputs":[],"source":["%%capture\n","!wget --no-check-certificate https://www.crcv.ucf.edu./data/UCF50.rar\n","!unrar x UCF50.rar"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kAE5eozyZbOT"},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","all_classes_name = os.listdir('/content/UCF50')\n","random_range = random.sample(range(len(all_classes_name)), 20) #start, 50, 20\n","for counter, random_index in enumerate(random_range, 1):\n","  selected_class_name = all_classes_name[random_index]\n","  video_files_name_list = os.listdir(f'/content/UCF50//{selected_class_name}')\n","  selected_video_file_name = random.choice(video_files_name_list)\n","  video_reader = cv2.VideoCapture(f'/content/UCF50/{selected_class_name}/{selected_video_file_name}')\n","  _, bgr_frame = video_reader.read()\n","  video_reader.release()\n","  #converting bgr to rgb\n","  rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n","  cv2.putText(rgb_frame, selected_class_name, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)\n","  plt.subplot(5,4,counter); plt.imshow(rgb_frame); plt.axis('off')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iuBze_zPaO9F"},"outputs":[],"source":["#Data Preprocessing\n","image_height, image_width = 64,64\n","sequence_length = 20\n","dataset_dir = '/content/UCF50'\n","classes_list = ['WalkingWithDog', 'TaiChi', 'Swing', 'HorseRace', 'Biking']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t7eHkY8Vadk9"},"outputs":[],"source":["#define a function to extract frames equally which gives equally distributed frames not the whole\n","def frames_extractions(video_path):\n","  frames_list = []\n","  video_reader = cv2.VideoCapture(video_path)\n","  video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n","  skip_frames_window = max(int(video_frames_count/sequence_length),1)\n","\n","  for frame_counter in range(sequence_length):\n","    video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter*skip_frames_window)\n","    success, frame = video_reader.read()\n","    if not success:\n","      break\n","    resized_frame = cv2.resize(frame, (image_height, image_width))\n","    normalized_frame = resized_frame/255\n","    frames_list.append(normalized_frame)\n","  video_reader.release()\n","  return frames_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g7USkYpRaf1Q"},"outputs":[],"source":["def create_dataset():\n","  features =[]\n","  labels = []\n","  video_files_paths = []\n","  for class_index, class_name in enumerate(classes_list):\n","    print(f'extracting data of class {class_name}')\n","    files_list = os.listdir(os.path.join(dataset_dir,class_name))\n","    for file_name in files_list:\n","      video_file_path = os.path.join(dataset_dir, class_name, file_name)\n","      frames=frames_extractions(video_path=video_file_path)\n","      if len(frames)==sequence_length:\n","        features.append(frames)\n","        labels.append(class_index)\n","        video_files_paths.append(video_file_path)\n","  features = np.asarray(features)\n","  labels = np.array(labels)\n","  return features, labels, video_files_paths"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2OokFTVajf6"},"outputs":[],"source":["data, lbl, paths = create_dataset()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s80gI4x-aok4"},"outputs":[],"source":["data.shape, lbl.shape\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uOxHT5wFa4j1"},"outputs":[],"source":["# plt.figure(figsize=(10,10))\n","# for i in range(len(data)):\n","#   plt.subplot(30,20,i+1)\n","#   plt.axis('off')\n","#   plt.imshow(data[i][0]);\n","# plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_6lZZhHa7m_"},"outputs":[],"source":["path = f'{dataset_dir}/{selected_class_name}/{selected_video_file_name}'\n","frames = frames_extractions(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dvGwsitVbVZ1"},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","for i in range(len(frames)):\n","  plt.subplot(4,5,i+1)\n","  plt.axis('off')\n","  plt.imshow(frames[i],'gray');\n","plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WBNq9ywDbXYR"},"outputs":[],"source":["#geting dataset\n","features, labels, video_files_paths = create_dataset()"]},{"cell_type":"code","source":["#now converting labels to onehot encoding.\n","one_hot_encoded_labels = to_categorical(labels)\n","one_hot_encoded_labels"],"metadata":{"id":"KRY41IJPfNLW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#splitting the data into train and test set\n","features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, test_size=0.25,random_state=seed_constant, shuffle=True)\n","print(f'Train features has:\\n\\t{features_train.shape}\\nTrain Labels has:\\n\\t{labels_train.shape}')"],"metadata":{"id":"ioo178zofNIU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n","\n","input_shape = (20, 64, 64, 3)\n","model = Sequential()\n","\n","# Add the first 3D convolutional layer with 64 filters, a kernel size of (3, 3, 3), and 'relu' activation\n","model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape))\n","model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n","\n","# Add additional convolutional and pooling layers for feature extraction\n","model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu'))\n","model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n","\n","model.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu'))\n","# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n","# Flatten the output to feed into a dense layer\n","model.add(Flatten())\n","\n","# Add a dense layer with dropout for regularization\n","model.add(Dense(256, activation='relu'))\n","model.add(Dropout(0.5))\n","\n","# Add the output layer with appropriate activation for your activity classes\n","model.add(Dense(len(classes_list), activation='softmax'))\n","\n","# Compile the model\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Display the model summary\n","model.summary()\n"],"metadata":{"id":"KlHO0yJifNGS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hist = model.fit(x=features_train, y=labels_train, epochs=50, batch_size=4,\n","                                          shuffle=True, validation_split=0.2)"],"metadata":{"id":"hYs5FCIefNDX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_evaluation = model.evaluate(x=features_test, y=labels_test)\n","\n","# Print the evaluation results\n","print(\"Test Loss:\", model_evaluation[0])\n","print(\"Test Accuracy:\", model_evaluation[1])\n"],"metadata":{"id":"P62f4KztfNAp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot training and validation loss\n","plt.figure(figsize=(12, 6))\n","plt.subplot(1, 2, 1)\n","plt.plot(hist.history['loss'], label='Training Loss')\n","plt.plot(hist.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","# Plot training and validation accuracy\n","plt.subplot(1, 2, 2)\n","plt.plot(hist.history['accuracy'], label='Training Accuracy')\n","plt.plot(hist.history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"CLyTf1w4fM9V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_cnn_rnn_model(sequence_length, image_height, image_width, classes_list):\n","    model = Sequential()\n","\n","    # CNN part\n","    model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu'), input_shape=(sequence_length, image_height, image_width, 3)))\n","    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n","    # model.add(TimeDistributed(Dropout(0.25)))\n","\n","    model.add(TimeDistributed(Conv2D(64, (3, 3), activation='relu')))\n","    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n","    # model.add(TimeDistributed(Dropout(0.25)))\n","\n","    model.add(TimeDistributed(Conv2D(128, (3, 3), activation='relu')))\n","    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n","    model.add(TimeDistributed(Dropout(0.25)))\n","\n","    model.add(TimeDistributed(Conv2D(256, (3, 3), activation='relu')))\n","    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n","    model.add(TimeDistributed(Dropout(0.25)))\n","\n","    # RNN part (SimpleRNN)\n","    model.add(TimeDistributed(Flatten()))\n","    model.add(SimpleRNN(64, return_sequences=False))  # Set return_sequences to False\n","\n","    # Dense layers\n","    model.add(Flatten())\n","    model.add(Dense(len(classes_list), activation='softmax'))\n","\n","    model.summary()\n","    return model\n","\n","\n","def create_convlstm_model():\n","  model = Sequential()\n","  model.add(ConvLSTM2D(filters=4, kernel_size=(3,3), activation='tanh', data_format='channels_last',\n","                       recurrent_dropout=0.2, return_sequences=True, input_shape=(sequence_length,image_height, image_width,3)))\n","  model.add(MaxPooling3D(pool_size=(1,2,2,), padding='same', data_format='channels_last'))\n","  model.add(TimeDistributed(Dropout(0.2)))\n","\n","  model.add(ConvLSTM2D(filters=8, kernel_size=(3,3), activation='tanh', data_format='channels_last', recurrent_dropout=0.2, return_sequences=True))\n","  model.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format='channels_last'))\n","  model.add(TimeDistributed(Dropout(0.2)))\n","\n","  model.add(ConvLSTM2D(filters=14, kernel_size=(3,3), activation='tanh', data_format='channels_last', recurrent_dropout=0.2, return_sequences=True))\n","  model.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format='channels_last'))\n","  model.add(TimeDistributed(Dropout(0.2)))\n","\n","  model.add(ConvLSTM2D(filters=16, kernel_size=(3,3), activation='tanh', data_format='channels_last', recurrent_dropout=0.2, return_sequences=True))\n","  model.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format='channels_last'))\n","  model.add(TimeDistributed(Dropout(0.2)))\n","\n","  model.add(Flatten())\n","  model.add(Dense(len(classes_list), activation='softmax'))\n","\n","  model.summary()\n","  return model\n"],"metadata":{"id":"Bfh2kEDVfM54"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create CNNRNN Model\n","# image_height, image_width = 64,64\n","# sequence_length = 20\n","classes_list=['WalkingWithDog', 'TaiChi', 'Swing', 'HorseRace', 'Biking']\n","cnn_rnn_model = create_cnn_rnn_model(sequence_length, image_height, image_width, classes_list)"],"metadata":{"id":"mpz4tNCyfJWS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Set your sequence length, image height, and image width accordingly\n","sequence_length = 20\n","image_height = 64\n","image_width = 64"],"metadata":{"id":"9aew8bQIxqz_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Early stopping callback\n","# early_stopping_callbacks = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, mode='min')\n","# Compile the model\n","cnn_rnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","# Training the model\n","cnn_rnn_model_history = cnn_rnn_model.fit(x=features_train, y=labels_train, epochs=50, batch_size=4,\n","                                          shuffle=True, validation_split=0.2)"],"metadata":{"id":"3DXuYdmYxuNQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_evaluation = cnn_rnn_model.evaluate(x=features_test, y=labels_test)\n","\n","# Print the evaluation results\n","print(\"Test Loss:\", model_evaluation[0])\n","print(\"Test Accuracy:\", model_evaluation[1])\n","\n","model.save(\"my_model.h5\")\n"],"metadata":{"id":"nIFvRy5NxwWY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot training and validation loss\n","plt.figure(figsize=(12, 6))\n","plt.subplot(1, 2, 1)\n","plt.plot(cnn_rnn_model_history.history['loss'], label='Training Loss')\n","plt.plot(cnn_rnn_model_history.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","# Plot training and validation accuracy\n","plt.subplot(1, 2, 2)\n","plt.plot(cnn_rnn_model_history.history['accuracy'], label='Training Accuracy')\n","plt.plot(cnn_rnn_model_history.history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"qy8nxJaiycSa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["convlstm_model = create_convlstm_model()\n"],"metadata":{"id":"EJuZdsXYyerf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["early_stopping_callbacks = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, mode='min')\n","convlstm_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n","convlstm_model_history = convlstm_model.fit(x=features_train, y=labels_train, epochs=50, batch_size=4,\n","                                            shuffle=True, validation_split=0.2, callbacks=[early_stopping_callbacks])"],"metadata":{"id":"PSt_ypS0yonE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_evaluation_history = convlstm_model.evaluate(x=features_test, y=labels_test)\n"],"metadata":{"id":"jx0SDDtWyrme"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#saving the model\n","from time import strftime\n","model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n","date_time_format = '%d_%m_%Y_%H_%M_%S'\n","current_date_time_dt = dt.datetime.now()\n","current_date_time = strftime(date_time_format)\n","model_file_name = f'Convlst_model__date_time_{current_date_time}__loss_{model_evaluation_loss*100:.2f}%__accuracy_{model_evaluation_accuracy*100:.2f}%.h5'\n","convlstm_model.save('/content/drive/MyDrive/FYP Studies/'+model_file_name, )"],"metadata":{"id":"MaCf3R4T2hHe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_metric(model_training_history, metric_name1, metric_name2):\n","  metric_value1 = model_training_history.history[metric_name1]\n","  metric_value2 = model_training_history.history[metric_name2]\n","\n","  epochs = range(len(metric_value1))\n","\n","  plt.plot(epochs, metric_value1, 'red', label=metric_name1)\n","  plt.plot(epochs, metric_value2, 'blue', label=metric_name2)\n","  plt.title(f'{metric_name1} vs {metric_name2}')\n","  plt.legend()"],"metadata":{"id":"HL6m8bEO28sf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_metric(convlstm_model_history, 'loss', 'val_loss')\n"],"metadata":{"id":"tO9yvN-42_1a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_metric(convlstm_model_history, 'accuracy', 'val_accuracy')\n"],"metadata":{"id":"MXBVmVxI3CPL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Training LRCNN\n","def create_LRCNN_model():\n","  model = Sequential()\n","  model.add(TimeDistributed(Conv2D(filters=16,kernel_size=(3,3), padding='same', activation='relu',\n","                                   input_shape=(sequence_length, image_height, image_width, 3))))\n","  model.add(TimeDistributed(MaxPool2D(pool_size=(4,4))))\n","  model.add(TimeDistributed(Dropout(0.25)))\n","\n","  model.add(TimeDistributed(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu')))\n","  model.add(TimeDistributed(MaxPool2D(pool_size=(4,4))))\n","  model.add(TimeDistributed(Dropout(0.25)))\n","\n","  model.add(TimeDistributed(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu')))\n","  model.add(TimeDistributed(MaxPool2D(pool_size=(4,4))))\n","  model.add(Dropout(0.25))\n","\n","  # model.add(TimeDistributed(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu')))\n","  # model.add(TimeDistributed(MaxPool2D(pool_size=(4,4))))\n","  # model.add(TimeDistributed(Dropout(0.25)))\n","\n","  model.add(TimeDistributed(Flatten()))\n","  model.add(LSTM(32))\n","\n","  model.add(Dense(len(classes_list), activation= 'softmax'))\n","  model.build(input_shape=(1, sequence_length, image_height, image_width, 3))\n","  model.summary()\n","\n","  return model\n"],"metadata":{"id":"Gv4AH1or3IA-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LRCNN_model = create_LRCNN_model()\n"],"metadata":{"id":"LYByuCNa3OB9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_model(convlstm_model, to_file='/content/drive/MyDrive/FYP Studies/LRCNN_model.png', show_shapes=True)\n"],"metadata":{"id":"JV4F4q1t3P3R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#training the LRCNN\n","LRCNN_early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True)\n","LRCNN_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","LRCNN_train_history = LRCNN_model.fit(x = features_train, y=labels_train, batch_size=4, epochs=50, validation_split=0.2, shuffle=True, callbacks=LRCNN_early_stopping)"],"metadata":{"id":"tIaT5HJr3T5v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LRCNN_val_history = LRCNN_model.evaluate(x=features_test, y=labels_test)\n"],"metadata":{"id":"xkroO7cE3jsz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#visualize the model\n","plot_metric(LRCNN_train_history, 'loss', 'val_loss')\n"],"metadata":{"id":"FQBy5SiD399X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot_metric(LRCNN_val_history, 'accuracy', 'val_accuracy')\n","plot_metric(LRCNN_train_history, 'accuracy', 'val_accuracy')"],"metadata":{"id":"UVyWzq4B4C-G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#saving the model\n","current_data_time = dt.datetime.now()\n","time_format = '%d_%m_%Y_%H_%M_%S'\n","formatted_date_time = strftime(time_format)\n","LRCNN_model.save('/content/drive/MyDrive/FYP Studies/LRCNN'+formatted_date_time+'.h5')"],"metadata":{"id":"Xw4GeJhJ4GWg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pytube import *\n","def download_video(video_url, output_dir):\n"," yt = YouTube(video_url)\n"," title = yt.title\n"," output_file_name = f'{output_dir}/{title}.mp4'\n"," mystream = yt.streams.get_highest_resolution()\n"," mystream.download(output_path=output_dir, filename=output_file_name)\n"," return title"],"metadata":{"id":"q8NibAUx4JCV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["url = 'https://youtu.be/g0LkJ2bv1rg'\n","output_dir = '/content/drive/MyDrive/FYP Studies/test_video'\n","\n","os.makedirs(output_dir, exist_ok=True)\n","video_title = download_video(url, output_dir)"],"metadata":{"id":"NyeoBAGt4Kkw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_on_video(video_file_path, output_file_path, sequence):\n","  video_reader = cv2.VideoCapture(video_file_path)\n","  frame_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","  frame_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n","\n","  return frame_height, frame_width"],"metadata":{"id":"wwJU18xW4NST"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# wget --no-check-certificate https://example.com/path/to/your/dataset.rar\n","#"],"metadata":{"id":"vUhnAMoG4U4_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LEpozwEQ5XVR"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPF67C229C/m+5PoZbpw3FL"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}